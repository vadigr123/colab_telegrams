{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadigr123/colab_telegrams/blob/main/SDXL_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required packages\n",
        "!pip install diffusers transformers accelerate telegram python-telegram-bot==20.3 realesrgan pillow --quiet\n",
        "import os\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "%cd /content\n",
        "\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import re\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import requests\n",
        "import json\n",
        "import urllib.parse\n",
        "import threading\n",
        "from diffusers import StableDiffusionXLPipeline, EulerAncestralDiscreteScheduler\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, CallbackQueryHandler, filters\n",
        "from io import BytesIO\n",
        "from collections import deque, defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Apply asyncio patch for nested loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load the main Stable Diffusion XL model\n",
        "print(\"Loading model...\")\n",
        "model_id = \"vadigr123/IndigoFurryMixXL_EPS3\"  # @param {type:\"string\"}\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# Generation parameters\n",
        "DEFAULT_WIDTH, DEFAULT_HEIGHT = 1024, 1024\n",
        "DEFAULT_STEPS = 30\n",
        "SEED = -1\n",
        "\n",
        "SIZE_PRESETS = {\n",
        "    \"square\": (1024, 1024),\n",
        "    \"wide\": (1216, 832),\n",
        "    \"tall\": (832, 1216)\n",
        "}\n",
        "\n",
        "# Global variables for the queue\n",
        "generation_queue = deque()\n",
        "active_generations = defaultdict(int)\n",
        "cancel_flags = defaultdict(bool)\n",
        "max_user_jobs = 3\n",
        "max_global_jobs = 5\n",
        "\n",
        "# Global variable to track loaded LoRAs\n",
        "loaded_loras = {}\n",
        "\n",
        "# Global dictionary to store generation details and images\n",
        "generation_details = {}\n",
        "stored_images = {}\n",
        "\n",
        "##############################################\n",
        "# Functions for loading LoRA models\n",
        "##############################################\n",
        "\n",
        "def download_things(directory, url, hf_token=\"\", civitai_api_key=\"\"):\n",
        "    url = url.strip()\n",
        "\n",
        "    # Use better filename logic\n",
        "    if \"civitai.com\" in url:\n",
        "        try:\n",
        "            # Extract model ID from URL for better filename\n",
        "            parsed_url = urllib.parse.urlparse(url)\n",
        "            if \"/models/\" in parsed_url.path:\n",
        "                model_id = parsed_url.path.split(\"/models/\")[-1].split(\"/\")[0]\n",
        "                filename = f\"{model_id}.safetensors\"\n",
        "            else:\n",
        "                # Try to get filename from Content-Disposition header\n",
        "                response = requests.head(url + f\"?token={civitai_api_key}\" if civitai_api_key else url, timeout=10)\n",
        "                content_disp = response.headers.get('Content-Disposition', '')\n",
        "                if 'filename=' in content_disp:\n",
        "                    filename = content_disp.split('filename=')[-1].strip('\"')\n",
        "                else:\n",
        "                    filename = \"model.safetensors\"\n",
        "        except:\n",
        "            filename = \"model.safetensors\"\n",
        "    else:\n",
        "        filename = url.split(\"/\")[-1].split(\"?\")[0]\n",
        "        if not filename or not filename.endswith('.safetensors'):\n",
        "            filename = \"model.safetensors\"\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    target_path = os.path.join(directory, filename)\n",
        "\n",
        "    if os.path.exists(target_path):\n",
        "        print(f\"‚úÖ File already exists: {target_path}\")\n",
        "        return target_path\n",
        "\n",
        "    try:\n",
        "        if \"drive.google.com\" in url:\n",
        "            original_dir = os.getcwd()\n",
        "            os.chdir(directory)\n",
        "            result = os.system(f\"gdown --fuzzy '{url}'\")\n",
        "            os.chdir(original_dir)\n",
        "            if result != 0:\n",
        "                raise Exception(\"Google Drive download failed\")\n",
        "\n",
        "        elif \"huggingface.co\" in url:\n",
        "            if \"/blob/\" in url:\n",
        "                url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "            if \"?download=true\" in url:\n",
        "                url = url.replace(\"?download=true\", \"\")\n",
        "\n",
        "            if hf_token:\n",
        "                result = os.system(f\"wget --header='Authorization: Bearer {hf_token}' -O '{target_path}' '{url}'\")\n",
        "            else:\n",
        "                result = os.system(f\"wget -O '{target_path}' '{url}'\")\n",
        "\n",
        "            if result != 0:\n",
        "                raise Exception(\"HuggingFace download failed\")\n",
        "\n",
        "        elif \"civitai.com\" in url:\n",
        "            if not civitai_api_key:\n",
        "                raise Exception(\"Civitai API key is required\")\n",
        "\n",
        "            # Add API key to URL\n",
        "            if \"?\" in url:\n",
        "                download_url = f\"{url}&token={civitai_api_key}\"\n",
        "            else:\n",
        "                download_url = f\"{url}?token={civitai_api_key}\"\n",
        "\n",
        "            result = os.system(f\"wget -O '{target_path}' '{download_url}'\")\n",
        "            if result != 0:\n",
        "                raise Exception(\"Civitai download failed - check your API key\")\n",
        "\n",
        "        else:\n",
        "            result = os.system(f\"wget -O '{target_path}' '{url}'\")\n",
        "            if result != 0:\n",
        "                raise Exception(\"Download failed\")\n",
        "\n",
        "        # Verify file was downloaded\n",
        "        if not os.path.exists(target_path) or os.path.getsize(target_path) == 0:\n",
        "            raise Exception(\"Downloaded file is empty or doesn't exist\")\n",
        "\n",
        "        print(f\"‚úÖ Successfully downloaded: {target_path}\")\n",
        "        return target_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clean up failed download\n",
        "        if os.path.exists(target_path):\n",
        "            os.remove(target_path)\n",
        "        raise e\n",
        "\n",
        "def get_model_list(directory_path):\n",
        "    \"\"\"Get list of all files in directory\"\"\"\n",
        "    model_list = []\n",
        "    if not os.path.exists(directory_path):\n",
        "        return model_list\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        # Skip directories and very small files\n",
        "        if os.path.isfile(file_path) and os.path.getsize(file_path) > 1024:\n",
        "            # Use original filename without extension as name\n",
        "            name_without_extension = os.path.splitext(filename)[0]\n",
        "            model_list.append((name_without_extension, file_path))\n",
        "    return model_list\n",
        "\n",
        "def apply_lora(pipe, lora_name, weight=1.0):\n",
        "    \"\"\"Load and apply LoRA to the pipeline\"\"\"\n",
        "    global lora_model_list, loaded_loras\n",
        "\n",
        "    # Find matching LoRA\n",
        "    matching = [model for model in lora_model_list if model[0].lower() == lora_name.lower()]\n",
        "    if not matching or matching[0][1] is None:\n",
        "        print(f\"‚ùå LoRA model '{lora_name}' not found\")\n",
        "        return False\n",
        "\n",
        "    lora_path = matching[0][1]\n",
        "    lora_key = f\"{lora_name}_{weight}\"\n",
        "\n",
        "    try:\n",
        "        # If this exact LoRA+weight combo is already loaded, skip\n",
        "        if lora_key in loaded_loras:\n",
        "            print(f\"‚úÖ LoRA {lora_name} (weight: {weight}) already loaded\")\n",
        "            return True\n",
        "\n",
        "        # Unload any existing LoRAs first\n",
        "        if hasattr(pipe, 'unload_lora_weights'):\n",
        "            pipe.unload_lora_weights()\n",
        "            loaded_loras.clear()\n",
        "\n",
        "        # Load the LoRA\n",
        "        pipe.load_lora_weights(lora_path, adapter_name=lora_name)\n",
        "\n",
        "        # Set the weight\n",
        "        if hasattr(pipe, 'set_adapters'):\n",
        "            pipe.set_adapters(lora_name, adapter_weights=[weight])\n",
        "\n",
        "        loaded_loras[lora_key] = lora_path\n",
        "        print(f\"‚úÖ Applied LoRA model: {lora_name} (weight: {weight})\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error applying LoRA {lora_name}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def clear_loras(pipe):\n",
        "    \"\"\"Clear all loaded LoRAs\"\"\"\n",
        "    global loaded_loras\n",
        "    try:\n",
        "        if hasattr(pipe, 'unload_lora_weights'):\n",
        "            pipe.unload_lora_weights()\n",
        "        loaded_loras.clear()\n",
        "        print(\"üßπ Cleared all LoRAs\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error clearing LoRAs: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def upscale_image(image, scale_factor=2):\n",
        "    \"\"\"Simple upscaling using PIL's LANCZOS resampling\"\"\"\n",
        "    try:\n",
        "        width, height = image.size\n",
        "        new_width = int(width * scale_factor)\n",
        "        new_height = int(height * scale_factor)\n",
        "\n",
        "        # Use LANCZOS for high-quality upscaling\n",
        "        upscaled = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "        return upscaled\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Upscaling error: {e}\")\n",
        "        return None\n",
        "\n",
        "def cleanup_old_details():\n",
        "    \"\"\"Clean up old generation details every hour\"\"\"\n",
        "    while True:\n",
        "        time.sleep(3600)  # Wait 1 hour\n",
        "        current_time = time.time()\n",
        "        keys_to_remove = []\n",
        "\n",
        "        for key in generation_details:\n",
        "            # Extract timestamp from key\n",
        "            try:\n",
        "                timestamp = int(key.split('_')[-1])\n",
        "                if current_time - timestamp > 86400:  # 24 hours\n",
        "                    keys_to_remove.append(key)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        for key in keys_to_remove:\n",
        "            del generation_details[key]\n",
        "            # Also clean up stored images\n",
        "            if key in stored_images:\n",
        "                del stored_images[key]\n",
        "\n",
        "# Folder for LoRA models\n",
        "directory_loras = 'loras'\n",
        "os.makedirs(directory_loras, exist_ok=True)\n",
        "\n",
        "# Configuration\n",
        "download_lora = \"\"  # @param {type:\"string\"}\n",
        "CIVITAI_API_KEY = \"\"  # @param {type:\"string\"}\n",
        "hf_token = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Download any specified LoRAs\n",
        "for url in [url.strip() for url in download_lora.split(',') if url.strip()]:\n",
        "    try:\n",
        "        downloaded_path = download_things(directory_loras, url, hf_token, CIVITAI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to download {url}: {e}\")\n",
        "\n",
        "# Update list of LoRA models\n",
        "lora_model_list = get_model_list(directory_loras)\n",
        "lora_model_list.insert(0, (\"None\", None))\n",
        "print(f\"\\033[33müèÅ Found {len(lora_model_list)-1} LoRA models.\\033[0m\")\n",
        "\n",
        "# Start cleanup thread\n",
        "cleanup_thread = threading.Thread(target=cleanup_old_details, daemon=True)\n",
        "cleanup_thread.start()\n",
        "\n",
        "##############################################\n",
        "# Telegram bot ‚Äì Commands\n",
        "##############################################\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data.setdefault(\"width\", DEFAULT_WIDTH)\n",
        "    context.user_data.setdefault(\"height\", DEFAULT_HEIGHT)\n",
        "    context.user_data.setdefault(\"steps\", DEFAULT_STEPS)\n",
        "    await update.message.reply_text(\n",
        "        \"Hello! Send a description for generation.\\n\\n\"\n",
        "        \"üìå /steps 30 ‚Äî set number of steps (30‚Äì50)\\n\"\n",
        "        \"üìå /size ‚Äî choose image size\\n\"\n",
        "        \"üìå /cancel ‚Äî cancel the current generation\\n\"\n",
        "        \"üìå /lora {url} ‚Äî download a LoRA model\\n\"\n",
        "        \"üìå /loras ‚Äî show list of LoRA models\\n\"\n",
        "        \"üìå /clear_loras ‚Äî clear all loaded LoRAs\\n\"\n",
        "        \"Also use <lora:name> or <lora:name:weight> in your prompt to apply LoRA.\"\n",
        "    )\n",
        "\n",
        "async def size_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"üü¶ 1024x1024\", callback_data=\"size_square\")],\n",
        "        [InlineKeyboardButton(\"üü• 1216x832\", callback_data=\"size_wide\")],\n",
        "        [InlineKeyboardButton(\"üü© 832x1216\", callback_data=\"size_tall\")]\n",
        "    ]\n",
        "    await update.message.reply_text(\"Choose a size:\", reply_markup=InlineKeyboardMarkup(keyboard))\n",
        "\n",
        "async def steps_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    args = context.args\n",
        "    if not args or not args[0].isdigit():\n",
        "        await update.message.reply_text(\"Enter a number between 30 and 50, e.g.: /steps 40\")\n",
        "        return\n",
        "    steps = int(args[0])\n",
        "    if 30 <= steps <= 50:\n",
        "        context.user_data[\"steps\"] = steps\n",
        "        await update.message.reply_text(f\"‚úÖ Steps set to: {steps}\")\n",
        "    else:\n",
        "        await update.message.reply_text(\"üö´ Only between 30 and 50 steps are allowed.\")\n",
        "\n",
        "async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    query = update.callback_query\n",
        "    await query.answer()\n",
        "    data = query.data\n",
        "\n",
        "    if data.startswith(\"size_\"):\n",
        "        size_key = data.split(\"_\")[1]\n",
        "        width, height = SIZE_PRESETS[size_key]\n",
        "        context.user_data[\"width\"] = width\n",
        "        context.user_data[\"height\"] = height\n",
        "        await query.edit_message_text(f\"‚úÖ Size set to: {width}x{height}\")\n",
        "\n",
        "    elif data.startswith(\"details_\"):\n",
        "        message_id = data.split(\"details_\")[1]\n",
        "        if message_id in generation_details:\n",
        "            details = generation_details[message_id]\n",
        "\n",
        "            # Create detailed message\n",
        "            detail_text = f\"üìã **Generation Details**\\n\\n\"\n",
        "            detail_text += f\"**Prompt:** {details['prompt']}\\n\\n\"\n",
        "            detail_text += f\"**Seed:** {details['seed']}\\n\"\n",
        "            detail_text += f\"**Dimensions:** {details['width']}x{details['height']}\\n\"\n",
        "            detail_text += f\"**Steps:** {details['steps']}\\n\"\n",
        "\n",
        "            if details['loras']:\n",
        "                detail_text += f\"**LoRA Models:**\\n\"\n",
        "                for lora in details['loras']:\n",
        "                    detail_text += f\"‚Ä¢ {lora}\\n\"\n",
        "            else:\n",
        "                detail_text += f\"**LoRA Models:** None\\n\"\n",
        "\n",
        "            # Send details as a new message\n",
        "            await query.message.reply_text(detail_text, parse_mode='Markdown')\n",
        "        else:\n",
        "            await query.message.reply_text(\"‚ùå Details not found (may have expired)\")\n",
        "\n",
        "    elif data.startswith(\"upscale_\"):\n",
        "        message_id = data.split(\"upscale_\")[1]\n",
        "        if message_id in stored_images:\n",
        "            try:\n",
        "                # Show progress message\n",
        "                progress_msg = await query.message.reply_text(\"üîç Upscaling image...\")\n",
        "\n",
        "                # Get the stored image\n",
        "                original_image = stored_images[message_id]\n",
        "\n",
        "                # Upscale the image (2x by default)\n",
        "                upscaled_image = upscale_image(original_image, scale_factor=2)\n",
        "\n",
        "                if upscaled_image:\n",
        "                    # Convert to bytes\n",
        "                    bio = BytesIO()\n",
        "                    bio.name = \"upscaled_image.png\"\n",
        "                    upscaled_image.save(bio, \"PNG\", optimize=True)\n",
        "                    bio.seek(0)\n",
        "\n",
        "                    # Get new dimensions\n",
        "                    new_width, new_height = upscaled_image.size\n",
        "\n",
        "                    # Delete progress message\n",
        "                    await progress_msg.delete()\n",
        "\n",
        "                    # Send upscaled image\n",
        "                    await query.message.reply_document(\n",
        "                        document=bio,\n",
        "                        filename=\"upscaled_image.png\",\n",
        "                        caption=f\"üîç Upscaled to {new_width}x{new_height} (2x scale)\"\n",
        "                    )\n",
        "                else:\n",
        "                    await progress_msg.edit_text(\"‚ùå Failed to upscale image\")\n",
        "            except Exception as e:\n",
        "                await query.message.reply_text(f\"‚ùå Upscaling error: {str(e)}\")\n",
        "        else:\n",
        "            await query.message.reply_text(\"‚ùå Original image not found (may have expired)\")\n",
        "\n",
        "    elif data.startswith(\"random_\"):\n",
        "        message_id = data.split(\"random_\")[1]\n",
        "        if message_id in generation_details:\n",
        "            details = generation_details[message_id]\n",
        "            user_id = query.from_user.id\n",
        "\n",
        "            # Check user limits\n",
        "            if active_generations[user_id] >= max_user_jobs:\n",
        "                await query.message.reply_text(\"üö´ You already have 3 active requests.\")\n",
        "                return\n",
        "            if len(generation_queue) >= max_global_jobs:\n",
        "                await query.message.reply_text(\"üö´ Queue is full. Try later.\")\n",
        "                return\n",
        "\n",
        "            # Reconstruct prompt with LoRA tags\n",
        "            original_prompt = details['prompt']\n",
        "            if details['loras']:\n",
        "                # Add LoRA tags back to prompt\n",
        "                lora_tags = \"\"\n",
        "                for lora_info in details['loras']:\n",
        "                    # Extract name and weight from \"name (weight: X.X)\" format\n",
        "                    if \" (weight: \" in lora_info:\n",
        "                        name = lora_info.split(\" (weight: \")[0]\n",
        "                        weight = lora_info.split(\" (weight: \")[1].rstrip(\")\")\n",
        "                        if weight == \"1.0\":\n",
        "                            lora_tags += f\"<lora:{name}> \"\n",
        "                        else:\n",
        "                            lora_tags += f\"<lora:{name}:{weight}> \"\n",
        "                    else:\n",
        "                        lora_tags += f\"<lora:{lora_info}> \"\n",
        "\n",
        "                original_prompt = lora_tags + original_prompt\n",
        "\n",
        "            # Create a fake update and context for generation\n",
        "            fake_message = type('obj', (object,), {\n",
        "                'text': original_prompt,\n",
        "                'from_user': query.from_user,\n",
        "                'reply_text': query.message.reply_text,\n",
        "                'reply_photo': query.message.reply_photo,\n",
        "                'reply_document': query.message.reply_document\n",
        "            })\n",
        "            fake_update = type('obj', (object,), {\n",
        "                'message': fake_message,\n",
        "                'effective_message': query.message\n",
        "            })\n",
        "\n",
        "            # Set user data to match original generation\n",
        "            context.user_data[\"width\"] = details['width']\n",
        "            context.user_data[\"height\"] = details['height']\n",
        "            context.user_data[\"steps\"] = details['steps']\n",
        "\n",
        "            # Start generation with random seed\n",
        "            await generate(fake_update, context, force_random_seed=True)\n",
        "        else:\n",
        "            await query.message.reply_text(\"‚ùå Generation data not found (may have expired)\")\n",
        "\n",
        "async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_id = update.message.from_user.id if update.message else None\n",
        "    if user_id:\n",
        "        cancel_flags[user_id] = True\n",
        "        await update.message.reply_text(\"üö´ Cancellation request sent.\")\n",
        "\n",
        "async def clear_loras_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Command to clear all loaded LoRAs\"\"\"\n",
        "    if clear_loras(pipe):\n",
        "        await update.message.reply_text(\"üßπ All LoRAs cleared successfully!\")\n",
        "    else:\n",
        "        await update.message.reply_text(\"‚ùå Error clearing LoRAs\")\n",
        "\n",
        "async def lora_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    args = context.args\n",
        "    if not args:\n",
        "        await update.message.reply_text(\n",
        "            \"Specify a URL to download a LoRA model, e.g.:\\n\"\n",
        "            \"/lora https://civitai.com/api/download/models/97655\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    url = args[0]\n",
        "    status_msg = await update.message.reply_text(\"‚è≥ Downloading LoRA model...\")\n",
        "\n",
        "    try:\n",
        "        # Validate URL\n",
        "        if not any(domain in url for domain in ['civitai.com', 'huggingface.co', 'drive.google.com']):\n",
        "            await status_msg.edit_text(\"‚ùå Unsupported URL. Only Civitai, HuggingFace, and Google Drive are supported.\")\n",
        "            return\n",
        "\n",
        "        # Check if Civitai URL and API key is available\n",
        "        if 'civitai.com' in url and not CIVITAI_API_KEY:\n",
        "            await status_msg.edit_text(\"‚ùå Civitai API key is required for downloading from Civitai.\")\n",
        "            return\n",
        "\n",
        "        # Download the model\n",
        "        downloaded_path = download_things(directory_loras, url, hf_token, CIVITAI_API_KEY)\n",
        "\n",
        "        # Update the global LoRA model list\n",
        "        global lora_model_list\n",
        "        lora_model_list = get_model_list(directory_loras)\n",
        "        lora_model_list.insert(0, (\"None\", None))\n",
        "\n",
        "        # Get the filename and size\n",
        "        filename = os.path.basename(downloaded_path)\n",
        "        lora_name = os.path.splitext(filename)[0]\n",
        "        file_size = os.path.getsize(downloaded_path) / (1024 * 1024)  # Size in MB\n",
        "\n",
        "        await status_msg.edit_text(\n",
        "            f\"‚úÖ LoRA model downloaded successfully!\\n\"\n",
        "            f\"üìÅ File: {filename}\\n\"\n",
        "            f\"üìè Size: {file_size:.1f} MB\\n\"\n",
        "            f\"üìù Use: <lora:{lora_name}> in your prompt\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        await status_msg.edit_text(f\"‚ùå Error downloading LoRA: {str(e)}\")\n",
        "        print(f\"LoRA download error: {e}\")\n",
        "\n",
        "async def loras_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    global lora_model_list\n",
        "    if len(lora_model_list) <= 1:  # Only \"None\" entry\n",
        "        await update.message.reply_text(\"üìÇ No LoRA models found.\\n\\nUse /lora {url} to download a LoRA model.\")\n",
        "        return\n",
        "\n",
        "    message = \"üìã Available LoRA models:\\n\\n\"\n",
        "\n",
        "    for name, path in lora_model_list:\n",
        "        if name.lower() == \"none\":\n",
        "            continue\n",
        "\n",
        "        # Get file info\n",
        "        file_size = 0\n",
        "        if path and os.path.exists(path):\n",
        "            file_size = os.path.getsize(path) / (1024 * 1024)  # Size in MB\n",
        "\n",
        "        # Simple display without special characters that break Markdown\n",
        "        message += f\"‚Ä¢ {name}\\n\"\n",
        "        message += f\"  Size: {file_size:.1f} MB\\n\"\n",
        "        message += f\"  Use: <lora:{name}> or <lora:{name}:0.8>\\n\\n\"\n",
        "\n",
        "    # Show currently loaded LoRAs\n",
        "    if loaded_loras:\n",
        "        message += \"üîÑ Currently loaded:\\n\"\n",
        "        for lora_key in loaded_loras:\n",
        "            message += f\"‚Ä¢ {lora_key}\\n\"\n",
        "        message += \"\\nüí° Use /clear_loras to unload all LoRAs\"\n",
        "\n",
        "    # Split message if too long (Telegram limit is ~4096 characters)\n",
        "    if len(message) > 4000:\n",
        "        # Send in parts\n",
        "        parts = message.split('\\n\\n')\n",
        "        current_part = \"üìã Available LoRA models:\\n\\n\"\n",
        "\n",
        "        for part in parts[1:]:  # Skip the header\n",
        "            if len(current_part) + len(part) + 2 > 4000:  # +2 for \\n\\n\n",
        "                await update.message.reply_text(current_part)\n",
        "                current_part = part + \"\\n\\n\"\n",
        "            else:\n",
        "                current_part += part + \"\\n\\n\"\n",
        "\n",
        "        if current_part.strip():\n",
        "            await update.message.reply_text(current_part)\n",
        "    else:\n",
        "        await update.message.reply_text(message)\n",
        "\n",
        "def create_progress_bar(progress):\n",
        "    full = int(progress / 10)\n",
        "    return f\"[{'üü©'*full}{'‚¨ú'*(10-full)}] {progress}%\"\n",
        "\n",
        "async def generate(update: Update, context: ContextTypes.DEFAULT_TYPE, force_random_seed=False):\n",
        "    # Check for text in message\n",
        "    if not update.message or not update.message.text:\n",
        "        if update.effective_message:\n",
        "            await update.effective_message.reply_text(\"‚ùå Error: No message text found!\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        prompt = update.message.text.strip()\n",
        "    except Exception as e:\n",
        "        await update.message.reply_text(f\"‚ùå Error retrieving prompt: {e}\")\n",
        "        return\n",
        "\n",
        "    user_id = update.message.from_user.id\n",
        "    if active_generations[user_id] >= max_user_jobs:\n",
        "        await update.message.reply_text(\"üö´ You already have 3 active requests.\")\n",
        "        return\n",
        "    if len(generation_queue) >= max_global_jobs:\n",
        "        await update.message.reply_text(\"üö´ Queue is full. Try later.\")\n",
        "        return\n",
        "\n",
        "    # Process LoRA tags: <lora:name> or <lora:name:weight>\n",
        "    lora_matches = re.findall(r\"<lora:([\\w\\-]+)(?::([\\d.]+))?>\", prompt, flags=re.IGNORECASE)\n",
        "    applied_loras = []\n",
        "    lora_errors = []\n",
        "\n",
        "    if lora_matches:\n",
        "        # Remove LoRA tags from prompt\n",
        "        prompt = re.sub(r\"<lora:[\\w\\-]+(?::[\\d.]+)?>\", \"\", prompt, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        # Clear existing LoRAs first\n",
        "        clear_loras(pipe)\n",
        "\n",
        "        # Apply each LoRA\n",
        "        for name, weight in lora_matches:\n",
        "            weight_val = float(weight) if weight else 1.0\n",
        "            success = apply_lora(pipe, name, weight_val)\n",
        "            if success:\n",
        "                applied_loras.append(f\"{name} (weight: {weight_val})\")\n",
        "            else:\n",
        "                lora_errors.append(name)\n",
        "\n",
        "    # Notify about LoRA errors\n",
        "    if lora_errors:\n",
        "        await update.message.reply_text(f\"‚ö†Ô∏è LoRA models not found: {', '.join(lora_errors)}\\n\\nUse /loras to see available models.\")\n",
        "\n",
        "    # Add task to global queue\n",
        "    task = (update, context, prompt)\n",
        "    generation_queue.append(task)\n",
        "    active_generations[user_id] += 1\n",
        "\n",
        "    # Inform user of queue position with live updates\n",
        "    position = list(generation_queue).index(task)\n",
        "    eta = position * 15  # approximate wait time in seconds\n",
        "    wait_msg = await update.message.reply_text(f\"üïì Waiting: [0/30] - position in queue: {position+1}, ETA ‚âà {eta}s\")\n",
        "    counter = 0\n",
        "\n",
        "    while position > 0:\n",
        "        if cancel_flags[user_id]:\n",
        "            generation_queue.remove(task)\n",
        "            active_generations[user_id] -= 1\n",
        "            cancel_flags[user_id] = False\n",
        "            await wait_msg.edit_text(\"‚ùå Generation cancelled before start.\")\n",
        "            return\n",
        "\n",
        "        # Update position\n",
        "        try:\n",
        "            position = list(generation_queue).index(task)\n",
        "            eta = position * 15\n",
        "        except ValueError:\n",
        "            position = 0  # Task not in queue anymore\n",
        "\n",
        "        counter = (counter % 30) + 1\n",
        "        await wait_msg.edit_text(f\"üïì Waiting: [{counter}/30] - position in queue: {position+1}, ETA ‚âà {eta}s\")\n",
        "        await asyncio.sleep(1)\n",
        "\n",
        "    # Start generation with live progress bar\n",
        "    try:\n",
        "        width = context.user_data.get(\"width\", DEFAULT_WIDTH)\n",
        "        height = context.user_data.get(\"height\", DEFAULT_HEIGHT)\n",
        "        steps = context.user_data.get(\"steps\", DEFAULT_STEPS)\n",
        "        generator = torch.Generator(\"cuda\")\n",
        "\n",
        "        # Force random seed if requested, otherwise use configured seed\n",
        "        if force_random_seed:\n",
        "            seed = random.randint(0, 2**32 - 1)\n",
        "        else:\n",
        "            seed = SEED if SEED != -1 else random.randint(0, 2**32 - 1)\n",
        "\n",
        "        generator.manual_seed(seed)\n",
        "\n",
        "        progress_msg = await update.message.reply_text(\"üîß Generation started...\")\n",
        "        for i in range(0, 101, 10):\n",
        "            if cancel_flags[user_id]:\n",
        "                await progress_msg.edit_text(\"‚ùå Generation cancelled.\")\n",
        "                if generation_queue and generation_queue[0] == task:\n",
        "                    generation_queue.popleft()\n",
        "                active_generations[user_id] -= 1\n",
        "                cancel_flags[user_id] = False\n",
        "                return\n",
        "            await progress_msg.edit_text(create_progress_bar(i))\n",
        "            await asyncio.sleep(1.5)\n",
        "\n",
        "        # Generate image\n",
        "        result = pipe(prompt, width=width, height=height, num_inference_steps=steps, generator=generator, output_type=\"pil\")\n",
        "        img = result.images[0]\n",
        "        bio = BytesIO()\n",
        "        bio.name = \"image.png\"\n",
        "        img.save(bio, \"PNG\")\n",
        "        bio.seek(0)\n",
        "\n",
        "        # Store generation details and image for buttons\n",
        "        message_id = f\"{user_id}_{int(time.time())}\"\n",
        "        generation_details[message_id] = {\n",
        "            'prompt': prompt,\n",
        "            'seed': seed,\n",
        "            'width': width,\n",
        "            'height': height,\n",
        "            'steps': steps,\n",
        "            'loras': applied_loras\n",
        "        }\n",
        "        # Store the PIL image for upscaling\n",
        "        stored_images[message_id] = img.copy()\n",
        "\n",
        "        # Create buttons: \"Show details\", \"Random seed\", and \"Upscale\"\n",
        "        keyboard = [\n",
        "            [\n",
        "                InlineKeyboardButton(\"üìã Details\", callback_data=f\"details_{message_id}\"),\n",
        "                InlineKeyboardButton(\"üé≤ Random\", callback_data=f\"random_{message_id}\"),\n",
        "                InlineKeyboardButton(\"üîç Upscale\", callback_data=f\"upscale_{message_id}\")\n",
        "            ]\n",
        "        ]\n",
        "        reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "        # Create short caption\n",
        "        lora_info = f\" ‚Ä¢ LoRA: {len(applied_loras)} applied\" if applied_loras else \"\"\n",
        "        caption = f\"üå± Seed: {seed} ‚Ä¢ üìè {width}x{height} ‚Ä¢ üßÆ Steps: {steps}{lora_info}\"\n",
        "\n",
        "        # Delete progress message\n",
        "        await progress_msg.delete()\n",
        "\n",
        "        # Send preview image with buttons\n",
        "        await update.message.reply_photo(\n",
        "            photo=bio,\n",
        "            caption=caption,\n",
        "            reply_markup=reply_markup\n",
        "        )\n",
        "\n",
        "        # Rewind and send as document for quality\n",
        "        bio.seek(0)\n",
        "        await update.message.reply_document(\n",
        "            document=bio,\n",
        "            filename=\"image.png\",\n",
        "            caption=\"High-quality image file\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        await update.message.reply_text(f\"‚ùå Error during generation: {e}\")\n",
        "        print(f\"Generation error: {e}\")\n",
        "    finally:\n",
        "        if generation_queue and generation_queue[0] == task:\n",
        "            generation_queue.popleft()\n",
        "        active_generations[user_id] -= 1\n",
        "        cancel_flags[user_id] = False\n",
        "\n",
        "##############################################\n",
        "# Run Telegram bot\n",
        "##############################################\n",
        "\n",
        "TOKEN = \"\" # @param {type:\"string\"}\n",
        "\n",
        "async def main():\n",
        "    TELEGRAM_BOT_TOKEN = os.environ.get(\"TELEGRAM_TOKEN\", TOKEN)\n",
        "    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()\n",
        "\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(CommandHandler(\"size\", size_command))\n",
        "    app.add_handler(CommandHandler(\"steps\", steps_command))\n",
        "    app.add_handler(CommandHandler(\"cancel\", cancel_command))\n",
        "    app.add_handler(CommandHandler(\"lora\", lora_command))\n",
        "    app.add_handler(CommandHandler(\"loras\", loras_command))\n",
        "    app.add_handler(CommandHandler(\"clear_loras\", clear_loras_command))\n",
        "    app.add_handler(CallbackQueryHandler(button_handler))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, generate))\n",
        "\n",
        "    await app.initialize()\n",
        "    await app.start()\n",
        "    print(\"‚úÖ Bot started\")\n",
        "    await app.updater.start_polling()\n",
        "    await asyncio.Event().wait()\n",
        "\n",
        "nest_asyncio.apply()\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411,
          "referenced_widgets": [
            "469a4ad076884ea79c9264471dc7352c",
            "357e0a3266c24a36845164d24024a3aa",
            "84ef3e4e4d8e4b24b8dd03a7c0e66e40",
            "cff7e13dd72b4a9d9d1a6248b7a5a24a",
            "df853169606b4a10837f9dec4ddfe87d",
            "67b38a7276b94c188d4b989ffcd42c00",
            "86ec528998204a42940bafa49c7a39e0",
            "b340c216a7c04d0facc111bff217b850",
            "3ffd4664b85149f78931d07364b4f091",
            "f991082fcc7c42d0b04c77f27adac57b",
            "99829e169d624704967e9e82f593e2ed",
            "2ff87cfbbbb145c39f93dd26e0497b18",
            "bb25e1b4a15b48f9a5eccd7475312dac",
            "09f4693b43ff4cabbc79307c54dfb801",
            "931ac87656bf42c2aa652dd8ad9f34c6",
            "50fe7f3a29634ef386e3c8828042eeea",
            "2c74d8555495429bb83e06c122b76956",
            "22abdd9d99984a5b8c97c25b69070f9d",
            "bfbe5e3374ee49dfafb2a0a258df644a",
            "10b53eaa0c4544d8a82938df663a7c64",
            "892aa994262c41b0a186fbce9442bc68",
            "9c23d64c0445409882a6672dbcd257a9",
            "59ebd04dfb394b2985816633e94f288a",
            "16e641e0d93d443ba2819188d5751df9",
            "73a860283a5d4e6f8fbb3c9a568b0a3e",
            "ef4d53d0ecb4485d8ad754db9e2021c8",
            "b2dadea9c73a431186a0919cded123da",
            "54bede5696e942c4b48a403ba05af694",
            "3d0507b666834cf3a53ab750d46d498f",
            "a309e7b707fd49529904a4ed4624066c",
            "2d82912a2a9e4605a2ed7f9c0e4d0727",
            "17cb8f9f82d6441882646a69748f4541",
            "bf1e02b492484af193d46ee99032c8ba"
          ]
        },
        "id": "kj2b-W6VDwip",
        "outputId": "02e24ea2-bc14-4882-b7ee-a1274224137e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469a4ad076884ea79c9264471dc7352c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "\u001b[33müèÅ Found 0 LoRA models.\u001b[0m\n",
            "‚úÖ Bot started\n",
            "‚úÖ Successfully downloaded: loras/lora_1610098.safetensors\n",
            "üßπ Cleared all LoRAs\n",
            "‚úÖ Applied LoRA model: 1610098 (weight: 1.0) from loras/lora_1610098.safetensors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ff87cfbbbb145c39f93dd26e0497b18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleared all LoRAs\n",
            "‚ùå LoRA model 'poyo' not found\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59ebd04dfb394b2985816633e94f288a"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOEtAdnt6L0pgqyxheSZvzn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "469a4ad076884ea79c9264471dc7352c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_357e0a3266c24a36845164d24024a3aa",
              "IPY_MODEL_84ef3e4e4d8e4b24b8dd03a7c0e66e40",
              "IPY_MODEL_cff7e13dd72b4a9d9d1a6248b7a5a24a"
            ],
            "layout": "IPY_MODEL_df853169606b4a10837f9dec4ddfe87d"
          }
        },
        "357e0a3266c24a36845164d24024a3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b38a7276b94c188d4b989ffcd42c00",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_86ec528998204a42940bafa49c7a39e0",
            "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
          }
        },
        "84ef3e4e4d8e4b24b8dd03a7c0e66e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b340c216a7c04d0facc111bff217b850",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ffd4664b85149f78931d07364b4f091",
            "value": 7
          }
        },
        "cff7e13dd72b4a9d9d1a6248b7a5a24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f991082fcc7c42d0b04c77f27adac57b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_99829e169d624704967e9e82f593e2ed",
            "value": "‚Äá7/7‚Äá[00:03&lt;00:00,‚Äá‚Äá1.42it/s]"
          }
        },
        "df853169606b4a10837f9dec4ddfe87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b38a7276b94c188d4b989ffcd42c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ec528998204a42940bafa49c7a39e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b340c216a7c04d0facc111bff217b850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffd4664b85149f78931d07364b4f091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f991082fcc7c42d0b04c77f27adac57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99829e169d624704967e9e82f593e2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ff87cfbbbb145c39f93dd26e0497b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb25e1b4a15b48f9a5eccd7475312dac",
              "IPY_MODEL_09f4693b43ff4cabbc79307c54dfb801",
              "IPY_MODEL_931ac87656bf42c2aa652dd8ad9f34c6"
            ],
            "layout": "IPY_MODEL_50fe7f3a29634ef386e3c8828042eeea"
          }
        },
        "bb25e1b4a15b48f9a5eccd7475312dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c74d8555495429bb83e06c122b76956",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_22abdd9d99984a5b8c97c25b69070f9d",
            "value": "100%"
          }
        },
        "09f4693b43ff4cabbc79307c54dfb801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbe5e3374ee49dfafb2a0a258df644a",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10b53eaa0c4544d8a82938df663a7c64",
            "value": 30
          }
        },
        "931ac87656bf42c2aa652dd8ad9f34c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_892aa994262c41b0a186fbce9442bc68",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9c23d64c0445409882a6672dbcd257a9",
            "value": "‚Äá30/30‚Äá[00:31&lt;00:00,‚Äá‚Äá1.05s/it]"
          }
        },
        "50fe7f3a29634ef386e3c8828042eeea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c74d8555495429bb83e06c122b76956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22abdd9d99984a5b8c97c25b69070f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfbe5e3374ee49dfafb2a0a258df644a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b53eaa0c4544d8a82938df663a7c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "892aa994262c41b0a186fbce9442bc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c23d64c0445409882a6672dbcd257a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ebd04dfb394b2985816633e94f288a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16e641e0d93d443ba2819188d5751df9",
              "IPY_MODEL_73a860283a5d4e6f8fbb3c9a568b0a3e",
              "IPY_MODEL_ef4d53d0ecb4485d8ad754db9e2021c8"
            ],
            "layout": "IPY_MODEL_b2dadea9c73a431186a0919cded123da"
          }
        },
        "16e641e0d93d443ba2819188d5751df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54bede5696e942c4b48a403ba05af694",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3d0507b666834cf3a53ab750d46d498f",
            "value": "100%"
          }
        },
        "73a860283a5d4e6f8fbb3c9a568b0a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a309e7b707fd49529904a4ed4624066c",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d82912a2a9e4605a2ed7f9c0e4d0727",
            "value": 30
          }
        },
        "ef4d53d0ecb4485d8ad754db9e2021c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17cb8f9f82d6441882646a69748f4541",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf1e02b492484af193d46ee99032c8ba",
            "value": "‚Äá30/30‚Äá[00:26&lt;00:00,‚Äá‚Äá1.08it/s]"
          }
        },
        "b2dadea9c73a431186a0919cded123da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54bede5696e942c4b48a403ba05af694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0507b666834cf3a53ab750d46d498f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a309e7b707fd49529904a4ed4624066c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d82912a2a9e4605a2ed7f9c0e4d0727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17cb8f9f82d6441882646a69748f4541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1e02b492484af193d46ee99032c8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}