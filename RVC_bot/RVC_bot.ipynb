{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5jqjgXYAYtqc"
      ],
      "authorship_tag": "ABX9TyM7hhTVdrtxfjF/hH8yCr+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadigr123/colab_telegrams/blob/main/RVC_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone & Download RVC"
      ],
      "metadata": {
        "id": "5jqjgXYAYtqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clone\n",
        "!git clone https://github.com/IAHispano/Applio --branch 3.2.9 --single-branch\n",
        "%cd /content/Applio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "9FoeenRfYuuO",
        "outputId": "dfb0d7be-4ad6-4c13-b0f8-6ce1e9646b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Applio'...\n",
            "remote: Enumerating objects: 17882, done.\u001b[K\n",
            "remote: Counting objects: 100% (1077/1077), done.\u001b[K\n",
            "remote: Compressing objects: 100% (345/345), done.\u001b[K\n",
            "remote: Total 17882 (delta 934), reused 736 (delta 732), pack-reused 16805 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17882/17882), 30.69 MiB | 24.72 MiB/s, done.\n",
            "Resolving deltas: 100% (11587/11587), done.\n",
            "Note: switching to '2614ccdf56ed6672755576f767988f7a20a956a5'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "/content/Applio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install\n",
        "\n",
        "!sudo apt update\n",
        "!sudo apt install python3.10\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --set python3 /usr/bin/python3.10\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.10/dist-packages')\n",
        "\n",
        "rot_47 = lambda encoded_text: \"\".join(\n",
        "    [\n",
        "        (\n",
        "            chr(\n",
        "                (ord(c) - (ord(\"a\") if c.islower() else ord(\"A\")) - 47) % 26\n",
        "                + (ord(\"a\") if c.islower() else ord(\"A\"))\n",
        "            )\n",
        "            if c.isalpha()\n",
        "            else c\n",
        "        )\n",
        "        for c in encoded_text\n",
        "    ]\n",
        ")\n",
        "\n",
        "!pip install uv\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Installing requirements...\")\n",
        "!uv pip install torch==2.7.0 torchvision torchaudio==2.7.0 --upgrade --index-url https://download.pytorch.org/whl/cu128 -q\n",
        "!uv pip install -r requirements.txt -q\n",
        "clear_output()\n",
        "print(\"Finished installing requirements! \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "nirEjCI-Yy5S",
        "outputId": "02feefed-f20b-4537-da68-57bbd53319c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished installing requirements! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download models\n",
        "!python core.py \"prerequisites\" --models \"True\" --exe \"True\"  --pretraineds_hifigan \"True\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "sDrLtKU1w53l",
        "outputId": "aefb282c-7f66-4816-e7be-9e02805ce009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_filename\n",
            "Downloading all files: 622MiB [00:09, 84.6MiB/s]No executables needed\n",
            "Downloading all files: 1.28GiB [00:24, 52.9MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Telegram RVC"
      ],
      "metadata": {
        "id": "v_vobBklY5e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download model\n",
        "# @markdown Hugging Face or Google Drive\n",
        "model_link = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "!python core.py download --model_link \"{model_link}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "q5L2E-xCY8up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQsHdKjQSKID",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Enhanced Applio Telegram Bot with Full Output Display\n",
        "# @markdown Shows all RVC processing output and errors directly in Telegram\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "import logging\n",
        "import subprocess\n",
        "import json\n",
        "from pathlib import Path\n",
        "import threading\n",
        "import time\n",
        "from IPython.display import Audio, display, clear_output\n",
        "import sys\n",
        "\n",
        "# Install required packages\n",
        "print(\"Installing Telegram bot dependencies...\")\n",
        "!pip install python-telegram-bot --upgrade -q\n",
        "clear_output()\n",
        "\n",
        "import telegram\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler\n",
        "\n",
        "# Configuration - UPDATE THESE VALUES\n",
        "BOT_TOKEN = \"\"  # @param {type:\"string\"}\n",
        "ADMIN_CHAT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Validate configuration\n",
        "if BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\" or not BOT_TOKEN:\n",
        "    print(\"❌ Please set your BOT_TOKEN!\")\n",
        "    raise SystemExit(\"Bot token not configured\")\n",
        "\n",
        "if ADMIN_CHAT_ID == \"YOUR_CHAT_ID_HERE\" or not ADMIN_CHAT_ID:\n",
        "    print(\"❌ Please set your ADMIN_CHAT_ID!\")\n",
        "    raise SystemExit(\"Admin chat ID not configured\")\n",
        "\n",
        "# Paths\n",
        "current_dir = \"/content/Applio\"\n",
        "logs_dir = os.path.join(current_dir, \"logs\")\n",
        "\n",
        "# Global variables\n",
        "user_sessions = {}\n",
        "bot_instance = None\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def log_print(message):\n",
        "    \"\"\"Print and log message\"\"\"\n",
        "    print(message)\n",
        "    logger.info(message)\n",
        "\n",
        "def get_available_models():\n",
        "    \"\"\"Get list of available voice models\"\"\"\n",
        "    log_print(f\"🔍 Checking models in: {logs_dir}\")\n",
        "\n",
        "    if not os.path.exists(logs_dir):\n",
        "        log_print(f\"❌ Logs directory not found: {logs_dir}\")\n",
        "        return []\n",
        "\n",
        "    models = []\n",
        "    try:\n",
        "        for item in os.listdir(logs_dir):\n",
        "            model_path = os.path.join(logs_dir, item)\n",
        "            if os.path.isdir(model_path):\n",
        "                # Check for .pth file (required)\n",
        "                files = os.listdir(model_path)\n",
        "                has_pth = any(f.endswith('.pth') for f in files)\n",
        "                if has_pth:\n",
        "                    models.append(item)\n",
        "                    log_print(f\"✓ Found model: {item}\")\n",
        "    except Exception as e:\n",
        "        log_print(f\"❌ Error reading models: {e}\")\n",
        "\n",
        "    log_print(f\"📊 Total models found: {len(models)}\")\n",
        "    return models\n",
        "\n",
        "def get_model_files(model_name):\n",
        "    \"\"\"Get .pth and .index files for a model - FIXED VERSION\"\"\"\n",
        "    model_folder = os.path.join(logs_dir, model_name)\n",
        "\n",
        "    if not os.path.exists(model_folder):\n",
        "        log_print(f\"❌ Model folder not found: {model_folder}\")\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        files = os.listdir(model_folder)\n",
        "        log_print(f\"📁 Files in {model_name}: {files}\")\n",
        "\n",
        "        # Find .pth file\n",
        "        pth_files = [f for f in files if f.endswith('.pth')]\n",
        "        if pth_files:\n",
        "            pth_path = os.path.join(model_folder, pth_files[0])\n",
        "            log_print(f\"✓ Found .pth file: {pth_files[0]}\")\n",
        "        else:\n",
        "            log_print(f\"❌ No .pth file found in {model_name}\")\n",
        "            return None, None\n",
        "\n",
        "        # Find .index file (optional)\n",
        "        index_files = [f for f in files if f.endswith('.index')]\n",
        "        if index_files:\n",
        "            index_path = os.path.join(model_folder, index_files[0])\n",
        "            log_print(f\"✓ Found .index file: {index_files[0]}\")\n",
        "        else:\n",
        "            log_print(f\"⚠️ No .index file found in {model_name} (optional)\")\n",
        "            index_path = None\n",
        "\n",
        "        # Verify paths exist\n",
        "        if pth_path and os.path.exists(pth_path):\n",
        "            log_print(f\"✅ .pth path verified: {pth_path}\")\n",
        "        else:\n",
        "            log_print(f\"❌ .pth path invalid: {pth_path}\")\n",
        "            return None, None\n",
        "\n",
        "        if index_path and os.path.exists(index_path):\n",
        "            log_print(f\"✅ .index path verified: {index_path}\")\n",
        "        elif index_path:\n",
        "            log_print(f\"❌ .index path invalid: {index_path}\")\n",
        "            index_path = None\n",
        "\n",
        "        return pth_path, index_path\n",
        "\n",
        "    except Exception as e:\n",
        "        log_print(f\"❌ Error getting model files for {model_name}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Start command\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    log_print(f\"👤 User {user_id} started bot\")\n",
        "\n",
        "    # Initialize user session\n",
        "    user_sessions[user_id] = {\n",
        "        'selected_model': None,\n",
        "        'processing': False,\n",
        "        'pitch': 0,\n",
        "        'volume_mix': 0.8,\n",
        "        'index_rate': 0.7,\n",
        "        'protect': 0.5,\n",
        "        'show_debug': True  # New: Enable debug output by default\n",
        "    }\n",
        "\n",
        "    welcome_text = \"\"\"\n",
        "🎵 **Welcome to Enhanced Applio Voice Converter!**\n",
        "\n",
        "**NEW FEATURE:** Full processing output visible! 📺\n",
        "\n",
        "**How to use:**\n",
        "1. `/models` - Select a voice model\n",
        "2. Send any audio file to convert\n",
        "3. Watch the live processing output! ✨\n",
        "\n",
        "**Commands:**\n",
        "• `/models` - Choose voice model\n",
        "• `/settings` - Adjust parameters\n",
        "• `/status` - Check current setup\n",
        "• `/debug` - Toggle debug output\n",
        "• `/help` - Show help\n",
        "\n",
        "**Debug Mode:** ON (you'll see all RVC processing details)\n",
        "\n",
        "Ready? Use `/models` to get started!\n",
        "    \"\"\"\n",
        "\n",
        "    await update.message.reply_text(welcome_text, parse_mode='Markdown')\n",
        "\n",
        "async def debug_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Toggle debug output\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    if user_id not in user_sessions:\n",
        "        await update.message.reply_text(\"❌ Use `/start` first!\")\n",
        "        return\n",
        "\n",
        "    session = user_sessions[user_id]\n",
        "    session['show_debug'] = not session.get('show_debug', True)\n",
        "\n",
        "    status = \"ON 📺\" if session['show_debug'] else \"OFF 🔇\"\n",
        "    await update.message.reply_text(\n",
        "        f\"🐛 **Debug Output:** {status}\\n\\n\" +\n",
        "        (\"You'll see all RVC processing details during conversion.\" if session['show_debug']\n",
        "         else \"Processing output will be hidden.\"),\n",
        "        parse_mode='Markdown'\n",
        "    )\n",
        "\n",
        "async def models_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Show available models\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    models = get_available_models()\n",
        "\n",
        "    if not models:\n",
        "        await update.message.reply_text(\n",
        "            \"❌ **No models found!**\\n\\nMake sure you have downloaded models to `/content/Applio/logs/`\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # Create buttons for models\n",
        "    keyboard = []\n",
        "    for model in models:\n",
        "        keyboard.append([InlineKeyboardButton(f\"🎭 {model}\", callback_data=f\"select_{model}\")])\n",
        "\n",
        "    keyboard.append([InlineKeyboardButton(\"🔄 Refresh\", callback_data=\"refresh\")])\n",
        "\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "    await update.message.reply_text(\n",
        "        f\"**🎭 Available Models ({len(models)}):**\\n\\nChoose a model for voice conversion:\",\n",
        "        reply_markup=reply_markup,\n",
        "        parse_mode='Markdown'\n",
        "    )\n",
        "\n",
        "async def settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Show settings\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    if user_id not in user_sessions:\n",
        "        await update.message.reply_text(\"❌ Use `/start` first!\")\n",
        "        return\n",
        "\n",
        "    session = user_sessions[user_id]\n",
        "\n",
        "    settings_text = f\"\"\"\n",
        "**⚙️ Current Settings:**\n",
        "\n",
        "🎵 **Pitch:** `{session['pitch']}`\n",
        "🔊 **Volume Mix:** `{session['volume_mix']}`\n",
        "📊 **Index Rate:** `{session['index_rate']}`\n",
        "🛡️ **Protect:** `{session['protect']}`\n",
        "🐛 **Debug Output:** `{'ON' if session.get('show_debug', True) else 'OFF'}`\n",
        "\n",
        "**Quick Pitch Settings:**\n",
        "    \"\"\"\n",
        "\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"🔽 -12\", callback_data=\"pitch_-12\"),\n",
        "         InlineKeyboardButton(\"🔽 -6\", callback_data=\"pitch_-6\"),\n",
        "         InlineKeyboardButton(\"⚪ 0\", callback_data=\"pitch_0\")],\n",
        "        [InlineKeyboardButton(\"🔼 +6\", callback_data=\"pitch_6\"),\n",
        "         InlineKeyboardButton(\"🔼 +12\", callback_data=\"pitch_12\"),\n",
        "         InlineKeyboardButton(\"🔄 Reset\", callback_data=\"reset\")]\n",
        "    ]\n",
        "\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "    await update.message.reply_text(settings_text, reply_markup=reply_markup, parse_mode='Markdown')\n",
        "\n",
        "async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Show current status\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    if user_id not in user_sessions:\n",
        "        await update.message.reply_text(\"❌ Use `/start` first!\")\n",
        "        return\n",
        "\n",
        "    session = user_sessions[user_id]\n",
        "    models = get_available_models()\n",
        "\n",
        "    status_text = f\"\"\"\n",
        "**📊 Current Status:**\n",
        "\n",
        "🎭 **Selected Model:** `{session['selected_model'] or 'None'}`\n",
        "⚡ **Processing:** `{'Yes' if session['processing'] else 'No'}`\n",
        "🤖 **Available Models:** `{len(models)}`\n",
        "🐛 **Debug Output:** `{'ON' if session.get('show_debug', True) else 'OFF'}`\n",
        "\n",
        "**Settings:**\n",
        "🎵 Pitch: `{session['pitch']}`\n",
        "🔊 Volume: `{session['volume_mix']}`\n",
        "📊 Index: `{session['index_rate']}`\n",
        "🛡️ Protect: `{session['protect']}`\n",
        "    \"\"\"\n",
        "\n",
        "    await update.message.reply_text(status_text, parse_mode='Markdown')\n",
        "\n",
        "async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Help command\"\"\"\n",
        "    help_text = \"\"\"\n",
        "**🎵 Enhanced Applio Voice Converter Help**\n",
        "\n",
        "**Quick Start:**\n",
        "1. `/models` - Select voice model\n",
        "2. Send audio file\n",
        "3. Watch live processing output! 📺\n",
        "\n",
        "**Commands:**\n",
        "• `/start` - Initialize bot\n",
        "• `/models` - Choose model\n",
        "• `/settings` - Adjust parameters\n",
        "• `/status` - Check setup\n",
        "• `/debug` - Toggle debug output\n",
        "• `/help` - This help\n",
        "\n",
        "**New Features:**\n",
        "📺 **Live Output** - See all RVC processing steps\n",
        "🐛 **Debug Mode** - Toggle detailed output\n",
        "⚡ **Real-time** - Updates during processing\n",
        "\n",
        "**Supported Audio:**\n",
        "📥 **Input:** MP3, WAV, OGG, Voice messages\n",
        "📤 **Output:** WAV format\n",
        "\n",
        "**Tips:**\n",
        "• Debug mode shows all processing details\n",
        "• Use `+12` pitch for female voice\n",
        "• Use `-12` pitch for male voice\n",
        "• Watch for error messages in real-time\n",
        "\n",
        "**Need help?** Contact admin!\n",
        "    \"\"\"\n",
        "\n",
        "    await update.message.reply_text(help_text, parse_mode='Markdown')\n",
        "\n",
        "async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Handle button clicks\"\"\"\n",
        "    query = update.callback_query\n",
        "    user_id = query.from_user.id\n",
        "    data = query.data\n",
        "\n",
        "    await query.answer()\n",
        "\n",
        "    if user_id not in user_sessions:\n",
        "        user_sessions[user_id] = {\n",
        "            'selected_model': None,\n",
        "            'processing': False,\n",
        "            'pitch': 0,\n",
        "            'volume_mix': 0.8,\n",
        "            'index_rate': 0.7,\n",
        "            'protect': 0.5,\n",
        "            'show_debug': True\n",
        "        }\n",
        "\n",
        "    session = user_sessions[user_id]\n",
        "\n",
        "    if data.startswith(\"select_\"):\n",
        "        # Model selection\n",
        "        model_name = data.replace(\"select_\", \"\")\n",
        "        session['selected_model'] = model_name\n",
        "        log_print(f\"✅ User {user_id} selected model: {model_name}\")\n",
        "\n",
        "        # Test model files immediately\n",
        "        pth_path, index_path = get_model_files(model_name)\n",
        "        if pth_path:\n",
        "            await query.edit_message_text(\n",
        "                f\"✅ **Model Selected:** `{model_name}`\\n🎵 Now send any audio file to convert!\\n📺 Debug output: {'ON' if session.get('show_debug') else 'OFF'}\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "        else:\n",
        "            await query.edit_message_text(\n",
        "                f\"❌ **Model Error:** `{model_name}`\\n\\nModel files not found or invalid.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "\n",
        "    elif data == \"refresh\":\n",
        "        # Refresh models list\n",
        "        models = get_available_models()\n",
        "        if not models:\n",
        "            await query.edit_message_text(\"❌ No models found!\")\n",
        "            return\n",
        "\n",
        "        keyboard = []\n",
        "        for model in models:\n",
        "            keyboard.append([InlineKeyboardButton(f\"🎭 {model}\", callback_data=f\"select_{model}\")])\n",
        "        keyboard.append([InlineKeyboardButton(\"🔄 Refresh\", callback_data=\"refresh\")])\n",
        "\n",
        "        reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "        await query.edit_message_text(\n",
        "            f\"**🎭 Available Models ({len(models)}):**\\n\\nChoose a model:\",\n",
        "            reply_markup=reply_markup,\n",
        "            parse_mode='Markdown'\n",
        "        )\n",
        "\n",
        "    elif data.startswith(\"pitch_\"):\n",
        "        # Pitch adjustment\n",
        "        pitch_value = int(data.replace(\"pitch_\", \"\"))\n",
        "        session['pitch'] = pitch_value\n",
        "        await query.edit_message_text(f\"✅ Pitch set to: **{pitch_value}**\", parse_mode='Markdown')\n",
        "\n",
        "    elif data == \"reset\":\n",
        "        # Reset settings\n",
        "        session.update({\n",
        "            'pitch': 0,\n",
        "            'volume_mix': 0.8,\n",
        "            'index_rate': 0.7,\n",
        "            'protect': 0.5\n",
        "        })\n",
        "        await query.edit_message_text(\"✅ **Settings reset to defaults!**\", parse_mode='Markdown')\n",
        "\n",
        "async def send_telegram_message(context, chat_id, message, max_length=4000):\n",
        "    \"\"\"Send message to Telegram with length limit handling\"\"\"\n",
        "    try:\n",
        "        if len(message) <= max_length:\n",
        "            await context.bot.send_message(chat_id=chat_id, text=message, parse_mode='Markdown')\n",
        "        else:\n",
        "            # Split long messages\n",
        "            parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]\n",
        "            for i, part in enumerate(parts):\n",
        "                if i == 0:\n",
        "                    await context.bot.send_message(chat_id=chat_id, text=f\"**Output (Part {i+1}/{len(parts)}):**\\n```\\n{part}\\n```\", parse_mode='Markdown')\n",
        "                else:\n",
        "                    await context.bot.send_message(chat_id=chat_id, text=f\"```\\n{part}\\n```\", parse_mode='Markdown')\n",
        "    except Exception as e:\n",
        "        # Fallback without markdown if formatting fails\n",
        "        try:\n",
        "            await context.bot.send_message(chat_id=chat_id, text=message[:max_length])\n",
        "        except:\n",
        "            await context.bot.send_message(chat_id=chat_id, text=f\"Error sending output: {str(e)[:500]}\")\n",
        "\n",
        "async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Handle audio files with full output display\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    chat_id = update.effective_chat.id\n",
        "    log_print(f\"🎵 User {user_id} sent audio\")\n",
        "\n",
        "    # Check user session\n",
        "    if user_id not in user_sessions:\n",
        "        await update.message.reply_text(\"❌ Use `/start` first!\")\n",
        "        return\n",
        "\n",
        "    session = user_sessions[user_id]\n",
        "\n",
        "    # Check if model is selected\n",
        "    if not session.get('selected_model'):\n",
        "        await update.message.reply_text(\"❌ Select a model first with `/models`\")\n",
        "        return\n",
        "\n",
        "    # Check if already processing\n",
        "    if session.get('processing'):\n",
        "        await update.message.reply_text(\"⏳ Already processing another file. Please wait...\")\n",
        "        return\n",
        "\n",
        "    # Set processing flag\n",
        "    session['processing'] = True\n",
        "\n",
        "    try:\n",
        "        # Send initial processing message\n",
        "        if session.get('show_debug', True):\n",
        "            status_msg = await update.message.reply_text(\n",
        "                \"🔄 **Starting Audio Processing...**\\n\\n📺 **Debug Mode ON** - You'll see all processing details!\\n\\n⏰ This may take 2-3 minutes\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "        else:\n",
        "            status_msg = await update.message.reply_text(\n",
        "                \"🔄 **Processing audio...**\\n\\nThis may take 2-3 minutes ⏰\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "\n",
        "        # Get file\n",
        "        if update.message.audio:\n",
        "            file = update.message.audio\n",
        "            extension = \".mp3\"\n",
        "        elif update.message.voice:\n",
        "            file = update.message.voice\n",
        "            extension = \".ogg\"\n",
        "        elif update.message.document and update.message.document.mime_type and 'audio' in update.message.document.mime_type:\n",
        "            file = update.message.document\n",
        "            extension = os.path.splitext(file.file_name or \"audio.wav\")[1] or \".wav\"\n",
        "        else:\n",
        "            await status_msg.edit_text(\"❌ **Unsupported file type!**\")\n",
        "            session['processing'] = False\n",
        "            return\n",
        "\n",
        "        if session.get('show_debug'):\n",
        "            await send_telegram_message(context, chat_id, f\"📁 **File Details:**\\n• Type: {extension}\\n• Size: {getattr(file, 'file_size', 'Unknown')} bytes\\n• Processing...\")\n",
        "\n",
        "        log_print(f\"📁 Processing {extension} file\")\n",
        "\n",
        "        # Download file\n",
        "        file_obj = await context.bot.get_file(file.file_id)\n",
        "        input_path = f\"/content/input_{user_id}{extension}\"\n",
        "        await file_obj.download_to_drive(input_path)\n",
        "\n",
        "        if session.get('show_debug'):\n",
        "            await send_telegram_message(context, chat_id, f\"⬇️ **Download Complete:**\\n• Path: `{input_path}`\\n• Size: {os.path.getsize(input_path)} bytes\")\n",
        "\n",
        "        log_print(f\"⬇️ Downloaded to: {input_path}\")\n",
        "\n",
        "        # Convert to WAV if needed\n",
        "        if not input_path.endswith('.wav'):\n",
        "            wav_path = f\"/content/input_{user_id}.wav\"\n",
        "\n",
        "            if session.get('show_debug'):\n",
        "                await send_telegram_message(context, chat_id, f\"🔄 **Converting to WAV:**\\n• From: {extension}\\n• To: .wav\\n• Sample rate: 44100 Hz\")\n",
        "\n",
        "            try:\n",
        "                result = subprocess.run([\n",
        "                    'ffmpeg', '-i', input_path, '-ar', '44100', '-ac', '1', '-y', wav_path\n",
        "                ], check=True, capture_output=True, text=True)\n",
        "\n",
        "                if session.get('show_debug') and result.stderr:\n",
        "                    await send_telegram_message(context, chat_id, f\"🔧 **FFmpeg Output:**\\n```\\n{result.stderr[-1000:]}\\n```\")\n",
        "\n",
        "                if os.path.exists(wav_path):\n",
        "                    os.remove(input_path)\n",
        "                    input_path = wav_path\n",
        "\n",
        "                    if session.get('show_debug'):\n",
        "                        await send_telegram_message(context, chat_id, f\"✅ **Conversion Success:**\\n• New path: `{input_path}`\\n• New size: {os.path.getsize(input_path)} bytes\")\n",
        "\n",
        "                    log_print(f\"🔄 Converted to WAV: {input_path}\")\n",
        "            except Exception as e:\n",
        "                error_msg = f\"⚠️ FFmpeg conversion failed: {e}\"\n",
        "                log_print(error_msg)\n",
        "                if session.get('show_debug'):\n",
        "                    await send_telegram_message(context, chat_id, f\"⚠️ **Conversion Warning:**\\n{error_msg}\\n\\nContinuing with original file...\")\n",
        "\n",
        "        # Process with Applio\n",
        "        success = await process_with_applio_enhanced(user_id, input_path, session, status_msg, context, chat_id)\n",
        "\n",
        "        if success:\n",
        "            output_path = f\"/content/output_{user_id}.wav\"\n",
        "\n",
        "            # Send result info\n",
        "            if session.get('show_debug'):\n",
        "                output_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0\n",
        "                await send_telegram_message(context, chat_id, f\"📤 **Conversion Complete!**\\n• Output size: {output_size} bytes\\n• Model: `{session['selected_model']}`\\n• Pitch: `{session['pitch']}`\\n\\nSending audio file...\")\n",
        "            else:\n",
        "                await status_msg.edit_text(\"📤 **Sending converted audio...**\", parse_mode='Markdown')\n",
        "\n",
        "            with open(output_path, 'rb') as audio_file:\n",
        "                await context.bot.send_audio(\n",
        "                    chat_id=chat_id,\n",
        "                    audio=audio_file,\n",
        "                    caption=f\"🎵 **Converted with:** `{session['selected_model']}`\\n🎛️ **Pitch:** `{session['pitch']}`\\n📺 **Debug mode:** `{'ON' if session.get('show_debug') else 'OFF'}`\",\n",
        "                    parse_mode='Markdown'\n",
        "                )\n",
        "\n",
        "            log_print(f\"✅ Successfully sent result to user {user_id}\")\n",
        "\n",
        "            # Cleanup\n",
        "            for path in [input_path, output_path]:\n",
        "                if os.path.exists(path):\n",
        "                    os.remove(path)\n",
        "\n",
        "            if session.get('show_debug'):\n",
        "                await send_telegram_message(context, chat_id, \"🧹 **Cleanup Complete** - Temporary files removed\")\n",
        "\n",
        "            await status_msg.delete()\n",
        "        else:\n",
        "            await status_msg.edit_text(\n",
        "                f\"❌ **Conversion failed!**\\n\\nTry:\\n• Different model\\n• Shorter audio file\\n• Check if model `{session['selected_model']}` exists\\n\\n📺 Check debug output above for details.\"\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Audio processing error: {e}\"\n",
        "        log_print(error_msg)\n",
        "\n",
        "        if session.get('show_debug'):\n",
        "            await send_telegram_message(context, chat_id, f\"**💥 Processing Error:**\\n```\\n{str(e)}\\n```\")\n",
        "        else:\n",
        "            await update.message.reply_text(f\"❌ **Error:** {str(e)}\")\n",
        "\n",
        "    finally:\n",
        "        session['processing'] = False\n",
        "\n",
        "async def process_with_applio_enhanced(user_id, input_path, session, status_msg, context, chat_id):\n",
        "    \"\"\"Process audio using Applio core.py with full output display\"\"\"\n",
        "    try:\n",
        "        show_debug = session.get('show_debug', True)\n",
        "        model_name = session['selected_model']\n",
        "\n",
        "        if show_debug:\n",
        "            await send_telegram_message(context, chat_id, f\"🎭 **Starting RVC Processing:**\\n• Model: `{model_name}`\\n• Checking model files...\")\n",
        "\n",
        "        log_print(f\"🎭 Processing with model: {model_name}\")\n",
        "\n",
        "        # Get model files with proper error handling\n",
        "        pth_path, index_path = get_model_files(model_name)\n",
        "\n",
        "        if not pth_path:\n",
        "            error_msg = f\"❌ Model files not found for: {model_name}\"\n",
        "            log_print(error_msg)\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, f\"**❌ Model Error:**\\n{error_msg}\")\n",
        "            return False\n",
        "\n",
        "        if show_debug:\n",
        "            await send_telegram_message(context, chat_id, f\"✅ **Model Files Found:**\\n• PTH: `{os.path.basename(pth_path)}`\\n• Index: `{os.path.basename(index_path) if index_path else 'None'}`\")\n",
        "\n",
        "        # Verify pth_path is a string, not tuple\n",
        "        if not isinstance(pth_path, str):\n",
        "            error_msg = f\"❌ Invalid pth_path type: {type(pth_path)} - {pth_path}\"\n",
        "            log_print(error_msg)\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, f\"**❌ Path Error:**\\n{error_msg}\")\n",
        "            return False\n",
        "\n",
        "        if not os.path.exists(pth_path):\n",
        "            error_msg = f\"❌ .pth file does not exist: {pth_path}\"\n",
        "            log_print(error_msg)\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, f\"**❌ File Missing:**\\n{error_msg}\")\n",
        "            return False\n",
        "\n",
        "        log_print(f\"📁 Using .pth: {pth_path}\")\n",
        "\n",
        "        # Handle index path\n",
        "        if index_path:\n",
        "            if not isinstance(index_path, str):\n",
        "                log_print(f\"⚠️ Invalid index_path type, ignoring: {type(index_path)}\")\n",
        "                index_path = None\n",
        "            elif not os.path.exists(index_path):\n",
        "                log_print(f\"⚠️ .index file does not exist, ignoring: {index_path}\")\n",
        "                index_path = None\n",
        "            else:\n",
        "                log_print(f\"📊 Using .index: {index_path}\")\n",
        "\n",
        "        output_path = f\"/content/output_{user_id}.wav\"\n",
        "\n",
        "        # Show processing parameters\n",
        "        if show_debug:\n",
        "            params_text = f\"\"\"🎛️ **Processing Parameters:**\n",
        "• Pitch: `{session['pitch']}`\n",
        "• Volume Mix: `{session['volume_mix']}`\n",
        "• Index Rate: `{session['index_rate']}`\n",
        "• Protect: `{session['protect']}`\n",
        "• F0 Method: `rmvpe`\n",
        "• Output Format: `WAV`\"\"\"\n",
        "            await send_telegram_message(context, chat_id, params_text)\n",
        "\n",
        "        # Build Applio command\n",
        "        cmd = [\n",
        "            \"python\", \"core.py\", \"infer\",\n",
        "            \"--pitch\", str(session['pitch']),\n",
        "            \"--volume_envelope\", str(session['volume_mix']),\n",
        "            \"--index_rate\", str(session['index_rate']),\n",
        "            \"--hop_length\", \"128\",\n",
        "            \"--protect\", str(session['protect']),\n",
        "            \"--f0_autotune\", \"False\",\n",
        "            \"--f0_method\", \"rmvpe\",\n",
        "            \"--input_path\", input_path,\n",
        "            \"--output_path\", output_path,\n",
        "            \"--pth_path\", pth_path,\n",
        "            \"--split_audio\", \"False\",\n",
        "            \"--clean_audio\", \"False\",\n",
        "            \"--clean_strength\", \"0.7\",\n",
        "            \"--export_format\", \"WAV\",\n",
        "            \"--embedder_model\", \"contentvec\",\n",
        "            \"--embedder_model_custom\", \"\",\n",
        "            \"--formant_shifting\", \"False\",\n",
        "            \"--formant_qfrency\", \"1.0\",\n",
        "            \"--formant_timbre\", \"1.0\",\n",
        "            \"--post_process\", \"False\",\n",
        "            \"--reverb\", \"False\",\n",
        "            \"--pitch_shift\", \"False\",\n",
        "            \"--limiter\", \"False\",\n",
        "            \"--gain\", \"False\",\n",
        "            \"--distortion\", \"False\",\n",
        "            \"--chorus\", \"False\",\n",
        "            \"--bitcrush\", \"False\",\n",
        "            \"--clipping\", \"False\",\n",
        "            \"--compressor\", \"False\",\n",
        "            \"--delay\", \"False\",\n",
        "            \"--reverb_room_size\", \"0.5\",\n",
        "            \"--reverb_damping\", \"0.5\",\n",
        "            \"--reverb_wet_gain\", \"0.0\",\n",
        "            \"--reverb_dry_gain\", \"0.0\",\n",
        "            \"--reverb_width\", \"1.0\",\n",
        "            \"--reverb_freeze_mode\", \"0.0\",\n",
        "            \"--pitch_shift_semitones\", \"0.0\",\n",
        "            \"--limiter_threshold\", \"-1.0\",\n",
        "            \"--limiter_release_time\", \"0.05\",\n",
        "            \"--gain_db\", \"0.0\",\n",
        "            \"--distortion_gain\", \"0.0\",\n",
        "            \"--chorus_rate\", \"1.5\",\n",
        "            \"--chorus_depth\", \"0.1\",\n",
        "            \"--chorus_center_delay\", \"15.0\",\n",
        "            \"--chorus_feedback\", \"0.25\",\n",
        "            \"--chorus_mix\", \"0.5\",\n",
        "            \"--bitcrush_bit_depth\", \"4\",\n",
        "            \"--clipping_threshold\", \"0.5\",\n",
        "            \"--compressor_threshold\", \"-20.0\",\n",
        "            \"--compressor_ratio\", \"4.0\",\n",
        "            \"--compressor_attack\", \"0.001\",\n",
        "            \"--compressor_release\", \"0.1\",\n",
        "            \"--delay_seconds\", \"0.1\",\n",
        "            \"--delay_feedback\", \"0.5\",\n",
        "            \"--delay_mix\", \"0.5\"\n",
        "        ]\n",
        "\n",
        "        # Add index path only if it exists and is valid\n",
        "        if index_path and isinstance(index_path, str) and os.path.exists(index_path):\n",
        "            cmd.extend([\"--index_path\", index_path])\n",
        "            log_print(\"✅ Added index path to command\")\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, \"✅ **Index file** will be used for better quality\")\n",
        "        else:\n",
        "            log_print(\"⚠️ No valid index path, proceeding without it\")\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, \"⚠️ **No index file** - proceeding without it (may affect quality)\")\n",
        "\n",
        "        if show_debug:\n",
        "            await send_telegram_message(context, chat_id, f\"🚀 **Starting RVC Core Process:**\\n• Command: `python core.py infer`\\n• Parameters: {len(cmd)-3} arguments\\n• Timeout: 5 minutes\")\n",
        "\n",
        "        log_print(f\"🔄 Running Applio command...\")\n",
        "        log_print(f\"📝 Command: python core.py infer [with {len(cmd)-3} parameters]\")\n",
        "\n",
        "        # Update status\n",
        "        await status_msg.edit_text(\"🤖 **Running AI conversion...**\\n\\n📺 Watch for live output below!\", parse_mode='Markdown')\n",
        "\n",
        "        # Run the command with real-time output capture\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            cwd=current_dir,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,  # Combine stderr with stdout\n",
        "            text=True,\n",
        "            universal_newlines=True,\n",
        "            bufsize=1  # Line buffered\n",
        "        )\n",
        "\n",
        "        output_lines = []\n",
        "        last_telegram_update = time.time()\n",
        "\n",
        "        # Read output line by line in real-time\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "\n",
        "            if line.strip():\n",
        "                output_lines.append(line.strip())\n",
        "                log_print(f\"📤 RVC: {line.strip()}\")\n",
        "\n",
        "                # Send updates to Telegram every 3 seconds or when important info appears\n",
        "                current_time = time.time()\n",
        "                is_important = any(keyword in line.lower() for keyword in [\n",
        "                    'error', 'fail', 'exception', 'loading', 'processing', 'complete',\n",
        "                    'model', 'audio', 'inference', 'pitch', 'index', 'converting'\n",
        "                ])\n",
        "\n",
        "                if show_debug and (current_time - last_telegram_update > 3 or is_important):\n",
        "                    # Send recent output (last 5 lines)\n",
        "                    recent_output = '\\n'.join(output_lines[-5:])\n",
        "                    if recent_output:\n",
        "                        await send_telegram_message(context, chat_id, f\"🔄 **RVC Live Output:**\\n```\\n{recent_output[-1500:]}\\n```\")\n",
        "                        last_telegram_update = current_time\n",
        "\n",
        "        # Wait for process to complete\n",
        "        return_code = process.wait()\n",
        "\n",
        "        # Get any remaining output\n",
        "        remaining_output, _ = process.communicate()\n",
        "        if remaining_output:\n",
        "            output_lines.extend(remaining_output.strip().split('\\n'))\n",
        "\n",
        "        log_print(f\"📊 Command completed with return code: {return_code}\")\n",
        "\n",
        "        # Send final output summary\n",
        "        if show_debug:\n",
        "            final_output = '\\n'.join(output_lines[-10:]) if output_lines else \"No output captured\"\n",
        "            await send_telegram_message(context, chat_id, f\"🏁 **RVC Process Complete:**\\n• Return Code: `{return_code}`\\n• Final Output:\\n```\\n{final_output[-1500:]}\\n```\")\n",
        "\n",
        "        # Check if output file was created\n",
        "        if os.path.exists(output_path):\n",
        "            file_size = os.path.getsize(output_path)\n",
        "            log_print(f\"✅ Output file created: {output_path} ({file_size} bytes)\")\n",
        "\n",
        "            if show_debug:\n",
        "                await send_telegram_message(context, chat_id, f\"✅ **Success!**\\n• Output file: `{output_path}`\\n• Size: {file_size} bytes\\n• Ready to send!\")\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            log_print(f\"❌ Output file not created: {output_path}\")\n",
        "\n",
        "            if show_debug:\n",
        "                error_summary = '\\n'.join([line for line in output_lines if any(keyword in line.lower() for keyword in ['error', 'fail', 'exception'])])\n",
        "                if error_summary:\n",
        "                    await send_telegram_message(context, chat_id, f\"❌ **Processing Failed:**\\n• No output file created\\n• Errors found:\\n```\\n{error_summary[-1000:]}\\n```\")\n",
        "                else:\n",
        "                    await send_telegram_message(context, chat_id, f\"❌ **Processing Failed:**\\n• No output file created\\n• No specific errors found\\n• Check full output above\")\n",
        "\n",
        "            return False\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        error_msg = \"⏰ Command timed out after 5 minutes\"\n",
        "        log_print(error_msg)\n",
        "        if show_debug:\n",
        "            await send_telegram_message(context, chat_id, f\"**⏰ Timeout Error:**\\n{error_msg}\\n\\nTry with a shorter audio file.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Processing error: {e}\"\n",
        "        log_print(error_msg)\n",
        "        if show_debug:\n",
        "            await send_telegram_message(context, chat_id, f\"**💥 Exception Error:**\\n```\\n{str(e)}\\n```\")\n",
        "        return False\n",
        "\n",
        "# Bot runner\n",
        "async def run_bot():\n",
        "    \"\"\"Run the Telegram bot\"\"\"\n",
        "    try:\n",
        "        # Create application\n",
        "        app = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "        # Add handlers\n",
        "        app.add_handler(CommandHandler(\"start\", start_command))\n",
        "        app.add_handler(CommandHandler(\"models\", models_command))\n",
        "        app.add_handler(CommandHandler(\"settings\", settings_command))\n",
        "        app.add_handler(CommandHandler(\"status\", status_command))\n",
        "        app.add_handler(CommandHandler(\"debug\", debug_command))  # New debug command\n",
        "        app.add_handler(CommandHandler(\"help\", help_command))\n",
        "        app.add_handler(CallbackQueryHandler(button_callback))\n",
        "        app.add_handler(MessageHandler(\n",
        "            filters.AUDIO | filters.VOICE | (filters.Document.AUDIO),\n",
        "            handle_audio\n",
        "        ))\n",
        "\n",
        "        models = get_available_models()\n",
        "        print(\"🤖 Enhanced Applio Telegram Bot Starting...\")\n",
        "        print(f\"📊 Found {len(models)} models: {models}\")\n",
        "        print(f\"📁 Applio directory: {current_dir}\")\n",
        "        print(\"📺 NEW: Full RVC output display enabled!\")\n",
        "        print(\"✅ Bot is ready! Send /start to begin.\")\n",
        "\n",
        "        # Start bot\n",
        "        await app.initialize()\n",
        "        await app.start()\n",
        "        await app.updater.start_polling()\n",
        "\n",
        "        # Keep running\n",
        "        while True:\n",
        "            await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Bot error: {e}\")\n",
        "        logger.error(f\"Bot error: {e}\")\n",
        "\n",
        "# Start the bot\n",
        "print(\"🚀 Starting Enhanced Applio Telegram Bot...\")\n",
        "print(\"📺 NEW FEATURES:\")\n",
        "print(\"   • Live RVC processing output\")\n",
        "print(\"   • Real-time error detection\")\n",
        "print(\"   • Debug mode toggle\")\n",
        "print(\"   • Full command output display\")\n",
        "print(\"🔧 Make sure your BOT_TOKEN and ADMIN_CHAT_ID are correct above\")\n",
        "\n",
        "# Run bot in Colab environment\n",
        "try:\n",
        "    # Check for existing event loop (Colab compatibility)\n",
        "    try:\n",
        "        loop = asyncio.get_running_loop()\n",
        "        print(\"📋 Using existing event loop\")\n",
        "        task = asyncio.create_task(run_bot())\n",
        "        print(\"✅ Enhanced bot started as background task!\")\n",
        "        print(\"🔄 Bot will run until you stop the cell or restart runtime\")\n",
        "        print(\"📺 Users will now see all RVC processing details!\")\n",
        "    except RuntimeError:\n",
        "        print(\"📋 Creating new event loop\")\n",
        "        asyncio.run(run_bot())\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"🛑 Bot stopped by user\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Startup error: {e}\")\n",
        "    print(\"💡 Try restarting the cell if issues persist\")"
      ]
    }
  ]
}